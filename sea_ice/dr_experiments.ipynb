{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel(fn, params, n_jobs=mp.cpu_count()):\n",
    "    pool = mp.Pool(n_jobs)\n",
    "    print('started new process pool with {} processes'.format(n_jobs))\n",
    "    try:\n",
    "        res = pool.map(fn, params)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    except:\n",
    "        print('process pool interrupted, shutting down')\n",
    "        pool.terminate()\n",
    "        pool.join()\n",
    "        raise\n",
    "    return res\n",
    "\n",
    "mplog = mp.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utilities ##\n",
    "\n",
    "from typing import Dict\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.utils.graph_shortest_path import graph_shortest_path\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def group_dict(iterable, keyfn, mapfn):\n",
    "    \"\"\"\n",
    "    Groups the iterable using the given key function and returns a dictionary\n",
    "    of keys to groups.\n",
    "    \"\"\"\n",
    "    groups = it.groupby(iterable, key=keyfn)\n",
    "    gdict = dict()\n",
    "    for k, g in groups:\n",
    "        gdict[k] = list(map(mapfn, g))\n",
    "    return gdict\n",
    "\n",
    "def stormid_dict(X_df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Partitions the storm forecast dataset into separate groups for each storm and\n",
    "    returns the result as a dictionary.\n",
    "    \"\"\"\n",
    "    groups = X_df.groupby(['stormid'])\n",
    "    storm_dict = dict()\n",
    "    for stormid, df in groups:\n",
    "        storm_dict[stormid] = df\n",
    "    return storm_dict\n",
    "\n",
    "def feature_groups(X_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Partitions X_df into three groups by columns:\n",
    "    1) 0-D features\n",
    "    2) 11x11 z, u, v wind reanalysis data\n",
    "    3) 11x11 sst, slp, humidity, and vorticity reanalysis data\n",
    "    \"\"\"\n",
    "    feat_cols = X_df.get(['instant_t', 'windspeed', 'latitude', 'longitude','hemisphere','Jday_predictor','initial_max_wind','max_wind_change_12h','dist2land'])\n",
    "    nature_cols = pd.get_dummies(X_df.nature, prefix='nature', drop_first=False)\n",
    "    basin_cols = pd.get_dummies(X_df.basin, prefix='basin', drop_first=False)\n",
    "    X_0D = pd.concat([feat_cols, nature_cols, basin_cols], axis=1, sort=False)\n",
    "    X_zuv = X_df.get([col for col in X_df.columns if col.startswith('z_') or col.startswith('u_') or col.startswith('v_')])\n",
    "    X_sshv = X_df.get([col for col in X_df.columns if col.startswith('sst') or col.startswith('slp')\n",
    "                   or col.startswith('hum') or col.startswith('vo700')])\n",
    "    return X_0D, X_zuv, X_sshv\n",
    "\n",
    "def trust_cont_score(X, X_map, k=10, alpha=0.5, impute_strategy='median'):\n",
    "    \"\"\"\n",
    "    Computes the \"trustworthiness\" and \"continuity\" [1] of X_map with respect to X.\n",
    "    This is a port and extension of the implementation provided by Van der Maaten [2].\n",
    "    \n",
    "    Parameters:\n",
    "    X     : the data in its original representation\n",
    "    X_map : the lower dimensional representation of the data to be evaluated\n",
    "    k     : parameter that determines the size of the neighborhood for the T&C measure\n",
    "    alpha : mixing parameter in [0,1] that determines the weight given to trustworthiness vs. continuity; higher values will give more\n",
    "            weight to trustworthiness, lower values to continuity.\n",
    "    \n",
    "    [1] Kaski S, Nikkilä J, Oja M, Venna J, Törönen P, Castrén E. Trustworthiness and metrics in visualizing similarity of gene expression. BMC bioinformatics. 2003 Dec;4(1):48.\n",
    "    [2] Maaten L. Learning a parametric embedding by preserving local structure. InArtificial Intelligence and Statistics 2009 Apr 15 (pp. 384-391).\n",
    "    \"\"\"\n",
    "    # Impute X values\n",
    "    X = Imputer(strategy=impute_strategy).fit_transform(X)\n",
    "    # Compute pairwise distance matrices\n",
    "    D_h = pairwise_distances(X, X, metric='euclidean')\n",
    "    D_l = pairwise_distances(X_map, X_map, metric='euclidean')\n",
    "    # Compute neighborhood indices\n",
    "    ind_h = np.argsort(D_h, axis=1)\n",
    "    ind_l = np.argsort(D_l, axis=1)\n",
    "    # Compute trustworthiness\n",
    "    N = X.shape[0]\n",
    "    T = 0\n",
    "    C = 0\n",
    "    t_ranks = np.zeros((k, 1))\n",
    "    c_ranks = np.zeros((k, 1))\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            t_ranks[j] = np.where(ind_h[i,:] == ind_l[i, j+1])\n",
    "            c_ranks[j] = np.where(ind_l[i,:] == ind_h[i, j+1])\n",
    "        t_ranks -= k\n",
    "        c_ranks -= k\n",
    "        T += np.sum(t_ranks[np.where(t_ranks > 0)])\n",
    "        C += np.sum(c_ranks[np.where(c_ranks > 0)])\n",
    "    S = (2 / (N * k * (2 * N - 3 * k - 1)))\n",
    "    T = 1.0 - S*T\n",
    "    C = 1.0 - S*C\n",
    "    return alpha*T + (1.0-alpha)*C\n",
    "\n",
    "def sammon_stress(X, X_m, impute_strategy='median'):\n",
    "    X = Imputer(strategy=impute_strategy).fit_transform(X)\n",
    "    Dx = pairwise_distances(X, X, metric='euclidean')\n",
    "    Dy = pairwise_distances(X_m, X_m, metric='euclidean')\n",
    "    # Sammon Stress computes sums over indices where i < j\n",
    "    # We can interpet this as being the upper triangle of each matrix, from the k=1 diagonal\n",
    "    Dx_ut = np.triu(Dx, k=1)\n",
    "    Dy_ut = np.triu(Dy, k=1)\n",
    "    # Compute Sammon Stress, S\n",
    "    S = (1 / np.sum(Dx_ut))*np.sum(np.square(Dx_ut - Dy_ut) / (Dx_ut + np.ones(Dx.shape)))\n",
    "    return S\n",
    "    \n",
    "    \n",
    "def residual_variance(X, X_m, n_neighbors=20):\n",
    "    kng_h = kneighbors_graph(X, n_neighbors=n_neighbors, mode='distance', n_jobs=mp.cpu_count()).toarray()\n",
    "    D_h = graph_shortest_path(kng_h, method='D', directed=False)\n",
    "    #D_h = pairwise_distances(X, X, metric='euclidean')\n",
    "    #D_l = kneighbors_graph(X_m, n_neighbors=50, mode='distance').toarray()\n",
    "    D_l = pairwise_distances(X_m, X_m, metric='euclidean')\n",
    "    r,_ = spearmanr(D_h.flatten(), D_l.flatten())\n",
    "    return 1 - r**2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X_df, n_components=2):\n",
    "    imputer = Imputer(strategy='median')\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_pipeline = Pipeline([('med_imputer', imputer),('scaler', scaler),('pca',pca)])\n",
    "    X_pc = pca_pipeline.fit_transform(X_df)    \n",
    "    return X_pc\n",
    "\n",
    "def rand_projection(X_df, n_components='auto', eps=0.1):\n",
    "    imputer = Imputer(strategy='median')\n",
    "    scaler = StandardScaler()\n",
    "    proj = SparseRandomProjection(n_components=n_components, eps=eps)\n",
    "    proj_pipeline = Pipeline([('med_imputer', imputer),('scaler', scaler),('proj', proj)])\n",
    "    X_rp = proj_pipeline.fit_transform(X_df)\n",
    "    return X_rp, proj.n_components_\n",
    "\n",
    "def tsne(X_df, n_components=2, n_iter=5000, perplexity=30, learning_rate=100, init='pca'):\n",
    "    imputer = Imputer(strategy='median')\n",
    "    scaler = StandardScaler()\n",
    "    tsne = TSNE(n_components=n_components, perplexity=perplexity, learning_rate=learning_rate, init=init, n_iter=n_iter)\n",
    "    tsne_pipeline = Pipeline([('med_imputer', imputer),('scaler', scaler),('tsne', tsne)])\n",
    "    X_tsne = tsne_pipeline.fit_transform(X_df)\n",
    "    print(\"t-SNE completed after {} iterations with final KLD: {}\".format(tsne.n_iter_, tsne.kl_divergence_))\n",
    "    return X_tsne\n",
    "\n",
    "def umap(X_df, n_components=2, y=None, n_neighbors=5, min_dist=0.1, metric='correlation'):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    imputer = Imputer(strategy='median')\n",
    "    scaler = StandardScaler()\n",
    "    umap = UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist, metric=metric)\n",
    "    umap_pipeline = Pipeline([('med_imputer', imputer),('scaler', scaler),('umap', umap)])\n",
    "    X_umap = umap_pipeline.fit_transform(X_df, y)\n",
    "    warnings.resetwarnings()\n",
    "    return X_umap\n",
    "\n",
    "def evaluate(X, X_maps, k=20, top_n=1, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Evaluates a collection of X_maps relative to X using the trustworthiness/continuity metric.\n",
    "    Returns 'top_n' tuples of (X_map, TC score, index)\n",
    "    \n",
    "    X      : the original, untransformed data\n",
    "    X_maps : an iterable of lower dimensional mappings to evaluate\n",
    "    k      : neighborhood parameter for T&C metric\n",
    "    top_n  : # of mappings to return, in descending order of score\n",
    "    \"\"\"\n",
    "    assert top_n <= len(X_maps)\n",
    "    scores = np.array([trust_cont_score(X, X_m, k=k, alpha=alpha) for X_m in X_maps])\n",
    "    sorted_inds = np.argsort(scores)[::-1]\n",
    "    sorted_scores = scores[sorted_inds]\n",
    "    sorted_maps = [X_maps[i] for i in sorted_inds]\n",
    "    return list(zip(sorted_maps, sorted_scores, sorted_inds))[:top_n]\n",
    "\n",
    "def plot_mapping_vs_y_2d(X_map, ys, title=\"\", xlabel=\"\", ylabel=\"\", instant_labels: pd.DataFrame = None):\n",
    "    plt.scatter(X_map[:,0], X_map[:,1], c=ys, cmap='copper')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.colorbar().set_label(\"Ice area\")\n",
    "    if instant_labels is not None:\n",
    "        for (i, xy) in enumerate(X_map):\n",
    "            if i % 2 == 0:\n",
    "                plt.annotate(instant_labels.values[i], xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ds = xr.open_dataset('data/train.nc')\n",
    "ys = np.load('data/train.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1500, 39, 58)\n"
     ]
    }
   ],
   "source": [
    "X_arr = X_ds.to_array()\n",
    "print(X_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Variable analysis\n",
    "\n",
    "Produce 2D visualizations for each individual variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rp(params):\n",
    "    X, d = params\n",
    "    return rand_projection(X, n_components=d)[0]\n",
    "\n",
    "def run_tsne(params):\n",
    "    X, d, perp = params\n",
    "    # Reduce dims with PCA\n",
    "    X_pc = pca(X, n_components=50)\n",
    "    return tsne(X_pc, perplexity=perp, init='random')\n",
    "\n",
    "def run_umap(params):\n",
    "    X, d, nn, min_dist = params\n",
    "    return umap(X, n_components=d, n_neighbors=nn, min_dist=min_dist)\n",
    "\n",
    "def run_rp_with_tc_cv(X, d=2, n_runs=24, k=20):\n",
    "    X_rps = parallel(run_rp, [(X, d)]*n_runs)\n",
    "    X_rp, tc, _ = evaluate(X, X_rps, k=k)[0]\n",
    "    return X_rp, tc\n",
    "\n",
    "def run_tsne_with_tc_cv(X, perplexities, d=2, k=20):\n",
    "    params = it.product([X], [d], perplexities)\n",
    "    X_tsnes = parallel(run_tsne, params)\n",
    "    X_tsne, tc, i = evaluate(X, X_tsnes, k=k)[0]\n",
    "    return X_tsne, tc, params[i][1:]\n",
    "\n",
    "def run_umap_with_tc_cv(X, n_neighbors, min_dists, d=2, k=20):\n",
    "    params = it.product([X], [d], n_neighbors, min_dists)\n",
    "    X_umaps = parallel(run_umap, params)\n",
    "    X_umap, tc, i = evaluate(X, X_umaps, k=k)[0]\n",
    "    return X_umap, tc, params[i][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running single variable tests for ice_area\n",
      "started new process pool with 8 processes\n",
      "started new process pool with 8 processes\n",
      "t-SNE completed after 2049 iterations with final KLD: 2.539768934249878\n",
      "t-SNE completed after 1699 iterations with final KLD: 2.2243263721466064\n",
      "t-SNE completed after 1699 iterations with final KLD: 1.983177900314331\n",
      "t-SNE completed after 4999 iterations with final KLD: 2.975492000579834\n",
      "started new process pool with 8 processes\n",
      "Running single variable tests for ts\n",
      "started new process pool with 8 processes\n",
      "started new process pool with 8 processes\n",
      "t-SNE completed after 4999 iterations with final KLD: 2.1451497077941895\n",
      "t-SNE completed after 4999 iterations with final KLD: 2.0397424697875977\n",
      "t-SNE completed after 4999 iterations with final KLD: 1.9198139905929565\n",
      "t-SNE completed after 4349 iterations with final KLD: 1.7984490394592285\n",
      "started new process pool with 8 processes\n",
      "Running single variable tests for taux\n",
      "started new process pool with 8 processes\n",
      "started new process pool with 8 processes\n",
      "t-SNE completed after 4999 iterations with final KLD: 2.3476152420043945\n",
      "t-SNE completed after 2449 iterations with final KLD: 1.9423353672027588\n",
      "t-SNE completed after 4999 iterations with final KLD: 2.1764309406280518\n",
      "t-SNE completed after 4399 iterations with final KLD: 2.1116554737091064\n",
      "started new process pool with 8 processes\n",
      "Running single variable tests for tauy\n",
      "started new process pool with 8 processes\n",
      "started new process pool with 8 processes\n",
      "t-SNE completed after 4999 iterations with final KLD: 2.3294334411621094\n",
      "t-SNE completed after 2599 iterations with final KLD: 2.0345523357391357\n",
      "t-SNE completed after 2349 iterations with final KLD: 1.921363115310669\n",
      "t-SNE completed after 4999 iterations with final KLD: 2.16682767868042\n",
      "started new process pool with 8 processes\n",
      "Running single variable tests for ps\n",
      "started new process pool with 8 processes\n",
      "started new process pool with 8 processes\n",
      "t-SNE completed after 4999 iterations with final KLD: 2.4967236518859863\n",
      "t-SNE completed after 2799 iterations with final KLD: 2.1368656158447266\n",
      "t-SNE completed after 2549 iterations with final KLD: 1.9737087488174438\n",
      "t-SNE completed after 4999 iterations with final KLD: 2.271644353866577\n",
      "started new process pool with 8 processes\n",
      "Running single variable tests for psl\n",
      "started new process pool with 8 processes\n",
      "started new process pool with 8 processes\n",
      "t-SNE completed after 2049 iterations with final KLD: 1.97920823097229\n",
      "t-SNE completed after 2599 iterations with final KLD: 2.1115522384643555\n",
      "t-SNE completed after 4999 iterations with final KLD: 2.4622366428375244\n",
      "t-SNE completed after 4999 iterations with final KLD: 2.2835946083068848\n",
      "started new process pool with 8 processes\n",
      "Running single variable tests for shflx\n",
      "started new process pool with 8 processes\n",
      "started new process pool with 8 processes\n",
      "t-SNE completed after 4999 iterations with final KLD: 1.7714147567749023\n",
      "t-SNE completed after 4999 iterations with final KLD: 1.6900314092636108\n",
      "t-SNE completed after 3049 iterations with final KLD: 1.5110080242156982\n",
      "t-SNE completed after 4849 iterations with final KLD: 1.597451090812683\n",
      "started new process pool with 8 processes\n",
      "Running single variable tests for cldtot\n",
      "started new process pool with 8 processes\n",
      "started new process pool with 8 processes\n"
     ]
    }
   ],
   "source": [
    "data_vars = list(X_ds.data_vars.keys())\n",
    "TC_k = 20\n",
    "tsne_perplexities = range(20, 100, 20)\n",
    "umap_nns = [10, 20, 50]\n",
    "umap_mds = np.arange(0.1, 1.0, 0.2)\n",
    "res_dict = dict()\n",
    "for (i, (var_name, X_var_3d)) in enumerate(zip(data_vars, X_arr.values)):\n",
    "    print('Running single variable tests for {}'.format(var_name))\n",
    "    # Flatten spatial dimensions\n",
    "    n_t, n_lat, n_lon = X_var_3d.shape[0], X_var_3d.shape[1], X_var_3d.shape[2]\n",
    "    X_var = X_var_3d.reshape((n_t, n_lat*n_lon))\n",
    "    assert(X_var.shape == (n_t, n_lat*n_lon))\n",
    "    res = []\n",
    "    # PCA\n",
    "    X_var_pc = pca(X_var, n_components=2)\n",
    "    tc_pc = trust_cont_score(X_var, X_var_pc, k=TC_k)\n",
    "    res.append((X_var_pc, tc_pc, \"PCA\"))\n",
    "    # Random projections\n",
    "    X_var_rp, tc_rp = run_rp_with_tc_cv(X_var, k=TC_k)\n",
    "    res.append((X_var_rp, tc_rp, \"RP\"))\n",
    "    # t-SNE\n",
    "    X_var_tsne, tc_tsne = run_tsne_with_tc_cv(X_var, tsne_perplexities, k=TC_k)\n",
    "    res.append((X_var_tsne, tc_tsne, \"t-SNE\"))\n",
    "    # UMAP\n",
    "    X_var_umap, tc_umap = run_umap_with_tc_cv(X_var, umap_nns, umap_mds, k=TC_k)\n",
    "    res.append((X_var_umap, tc_umap, \"UMAP\"))\n",
    "    # Store results for variable\n",
    "    res_dict[var_name] = res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plots_per_var = 4\n",
    "plt.figure(figsize=(25,45))\n",
    "for (i, (var_name, maps)) in enumerate(res_dict.items()):\n",
    "    for (j, (X_2d, tc, name)) in enumerate(maps):\n",
    "        plt.subplot(len(data_vars), n_plots_per_var, i*n_plots_per_var + j + 1)\n",
    "        plot_mapping_vs_y_2d(X_2d, ys, \"{}, {} 2D (TC={:.3f})\".format(var_name, name, tc))\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap variable and time axes\n",
    "X_swap = np.swapaxes(X_arr.values, 0, 1)\n",
    "# Flatten variable and spatial dimensions\n",
    "n_t, n_vars, n_lat, n_lon = X_swap.shape[0], X_swap.shape[1], X_swap.shape[2], X_swap.shape[3]\n",
    "X_full = X_swap.reshape((n_t, n_vars*n_lat*n_lon))\n",
    "assert(X_full.shape == (n_t, n_vars*n_lat*n_lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCA on full feature set\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dd0ace28ba2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# PCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running PCA on full feature set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_full_pc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtc_pc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrust_cont_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_full_pc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTC_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_full_pc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtc_pc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PCA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5212a1a14f1b>\u001b[0m in \u001b[0;36mpca\u001b[0;34m(X_df, n_components)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpca_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'med_imputer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scaler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pca'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_pc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_pc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \"\"\"\n\u001b[1;32m    280\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/imputation.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    164\u001b[0m                                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                                                    self.axis)\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/imputation.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, strategy, missing_values, axis)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 masked_X.mask = np.logical_or(masked_X.mask,\n\u001b[1;32m    272\u001b[0m                                               np.isnan(X))\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mmedian_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;31m# Avoid the warning \"Warning: converting a masked element to nan.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mmedian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedian_masked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/ma/extras.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m--> 693\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m    694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   4014\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4016\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4017\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/ma/extras.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0masorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         \u001b[0masorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36msort\u001b[0;34m(a, axis, kind, order, endwith, fill_value)\u001b[0m\n\u001b[1;32m   6635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6636\u001b[0m         a.sort(axis=axis, kind=kind, order=order,\n\u001b[0;32m-> 6637\u001b[0;31m                endwith=endwith, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   6638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6639\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36msort\u001b[0;34m(self, axis, kind, order, endwith, fill_value)\u001b[0m\n\u001b[1;32m   5544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5545\u001b[0m         sidx = self.argsort(axis=axis, kind=kind, order=order,\n\u001b[0;32m-> 5546\u001b[0;31m                             fill_value=fill_value, endwith=endwith)\n\u001b[0m\u001b[1;32m   5547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5548\u001b[0m         \u001b[0;31m# save memory for 1d arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(self, axis, kind, order, endwith, fill_value)\u001b[0m\n\u001b[1;32m   5391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5392\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5393\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5395\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TC_k = 20\n",
    "tsne_perplexities = range(20, 100, 20)\n",
    "umap_nns = [10, 20, 50]\n",
    "umap_mds = np.arange(0.1, 1.0, 0.2)\n",
    "res = []\n",
    "# PCA\n",
    "print('Running PCA on full feature set')\n",
    "X_full_pc = pca(X_full, n_components=2)\n",
    "tc_pc = trust_cont_score(X_full, X_full_pc, k=TC_k)\n",
    "res.append((X_full_pc, tc_pc, \"PCA\"))\n",
    "# Random projections\n",
    "print('Running RP on full feature set')\n",
    "X_full_rp, tc_rp = run_rp_with_tc_cv(X_full, k=TC_k)\n",
    "res.append((X_full_rp, tc_rp, \"RP\"))\n",
    "# t-SNE\n",
    "print('Running t-SNE on full feature set')\n",
    "X_full_tsne, tc_tsne, params_tsne = run_tsne_with_tc_cv(X_full, tsne_perplexities, k=TC_k)\n",
    "res.append((X_full_tsne, tc_tsne, \"t-SNE\"))\n",
    "print(params_tsne)\n",
    "# UMAP\n",
    "print('Running UMAP on full feature set')\n",
    "X_full_umap, tc_umap, params_umap = run_umap_with_tc_cv(X_full, umap_nns, umap_mds, k=TC_k)\n",
    "res.append((X_full_umap, tc_umap, \"UMAP\"))\n",
    "print(params_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(1, 4, 1)\n",
    "plot_mapping_vs_y_2d(X_full_pc, ys, \"PCA 2D (TC={:.3f})\".format(tc_pc))\n",
    "plt.subplot(1, 4, 2)\n",
    "plot_mapping_vs_y_2d(X_full_rp, ys, \"RP 2D (TC={:.3f})\".format(tc_rp))\n",
    "plt.subplot(1, 4, 3)\n",
    "plot_mapping_vs_y_2d(X_full_tsne, ys, \"t-SNE 2D (TC={:.3f})\".format(tc_tsne))\n",
    "plt.subplot(1, 4, 4)\n",
    "plot_mapping_vs_y_2d(X_full_umap, ys, \"UMAP 2D (TC={:.3f})\".format(tc_umap))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of performance in higher dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_hi = X_full.shape[1]\n",
    "log_lim = np.floor(np.log2(d_hi)) - 1\n",
    "ds = np.logspace(0, log_lim, num=log_lim + 1, base=2.0)\n",
    "X_hi = X_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "def run_pca(d):\n",
    "    return pca(X_hi, d)\n",
    "\n",
    "# Random projection parameters\n",
    "n_runs = 20\n",
    "rp_params = ds\n",
    "def run_rp(d):\n",
    "    return rand_projection(X_hi, d)\n",
    "\n",
    "# UMAP parameters\n",
    "n_neighbors = np.arange(20, 100, 20)\n",
    "min_dists = np.arange(0.1, 1.0, 0.2)\n",
    "umap_params = list(it.product(ds, n_neighbors, min_dists))\n",
    "def run_umap(x):\n",
    "    d, nn, md = x\n",
    "    return umap(X_hi, n_components=d, n_neighbors=nn, min_dist=md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running PCA with {} configurations'.format(len(ds)))\n",
    "X_lo_pca = parallel(run_pca, ds)\n",
    "res_pca = list(zip(ds, X_lo_pca))\n",
    "print('Running RP with {} configurations'.format(len(ds)))\n",
    "X_lo_rp = parallel(run_rp, ds)\n",
    "res_rp = list(zip(ds, X_lo_rp))\n",
    "#print('Running t-SNE with {} configurations'.format(len(tsne_params)))\n",
    "#res_tsne = zip(tsne_params, parallel(run_tsne, tsne_params))\n",
    "print('Running UMAP with {} configurations'.format(len(umap_params)))\n",
    "X_lo_umap = parallel(run_umap, umap_params)\n",
    "res_umap = list(zip(ds, X_lo_umap))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_groups = group_dict(res_pca, lambda x: x[0], lambda x: x[1])\n",
    "rp_groups = group_dict(res_rp, lambda x: x[0], lambda x: x[1])\n",
    "umap_groups = group_dict(res_umap, lambda x: x[0][0], lambda x: x[1])\n",
    "\n",
    "def compute_trustworthiness_scores(d):\n",
    "    print('Computing trustworthiness values for d={}'.format(d))\n",
    "    _, tc_pca, _ = evaluate(X_hi, pca_groups[d], k=10)[0]\n",
    "    _, tc_rp, _ = evaluate(X_hi, rp_groups[d], k=10)[0]\n",
    "    _, tc_umap, i = evaluate(X_hi, umap_groups[d], k=10)[0]\n",
    "    print('best params UMAP: {}'.format(umap_params[i]))\n",
    "    return tc_pca, tc_rp, tc_umap\n",
    "\n",
    "ts_all = parallel(compute_trustworthiness_scores, ds)\n",
    "ts_pca, ts_rp, ts_umap = zip(*ts_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds, ts_pca)\n",
    "plt.plot(ds, ts_rp)\n",
    "plt.plot(ds, ts_umap)\n",
    "plt.legend(['PCA', 'RP', 'UMAP'])\n",
    "plt.title('T&C score vs d for 0D features\\n (higher is better)')\n",
    "plt.xlabel('Dimensionality of embdding (d)')\n",
    "plt.ylabel('Trust/Cont score (k=10)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
